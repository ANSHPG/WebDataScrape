# -*- coding: utf-8 -*-
"""webscrapping_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15a7Agg_tMAyEUMp8bOOqLJS9rpXnmnhL

**WEB SCRAPPING | ANSHUMAN PATTNAIK**
"""

import pandas as pd
import requests
from bs4 import BeautifulSoup

url = 'https://internshala.com/jobs/page-1/'

headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}
webpage = requests.get(url,headers=headers).text

soup = BeautifulSoup(webpage,'lxml')
print(soup.prettify())

card_container = 'container-fluid'
company2 = soup.find_all('div',class_='individual_internship_details')
ctc3 = soup.find_all('div',class_='other_detail_item salary_container')
exp5 = soup.find_all('div',class_='other_detail_item job-experience-item')
job_profile = soup.find_all('h3',class_='heading_4_5 profile')
company_name = soup.find_all('div',class_='heading_6 company_name')
logo9 = soup.find_all('div',class_='internship_logo')

"""**LOCATION**"""

location = []
for i in company2:
  x3 = i.find('span')
  location.append(x3.text.strip())

"""**COST TO COMPANY [CTC]**"""

ctc = []
for i in ctc3:
  x4 = i.find('span',class_='desktop')
  ctc.append(x4.text.strip())

"""**EXPERIENCE**"""

exp = []
for i in exp5:
  x5 = i.find('div',class_='item_body desktop-text')
  exp.append(x5.text.strip())

"""**ARRAY CREATION**"""

job = []
cmpname = []
logo = []

"""**JOB PROFILE**"""

for i in job_profile:
  x7 = i.text.strip()
  job.append(x7)

"""**COMPANY NAME**"""

for i in company_name:
  x8 = i.find('p')
  cmpname.append(x8.text.strip())

"""**LOGO IMG**"""

for i in logo9:
  x9 = i.find('img')
  if x9:
    logo.append(x9['src'])
  else :
    logo.append('none')

"""know the length of series"""

print(len(job))
print(len(cmpname))
print(len(logo))
print(len(location))
print(len(ctc))
print(len(exp))

merge = {'Job Profile':job,'Company':cmpname,'Location':location,'CTC':ctc,'EXPERIENCE':exp,'LOGO':logo}

merge = pd.DataFrame(merge)

merge

logo[13] # to check wheter our rows are correct or not - it is correct - GC MARKETING COMPANY

"""**FROM PAGES RANGE [1:n]**"""

data = pd.DataFrame()

for i in range(1,11):

  url2= url = 'https://internshala.com/jobs/page-{}/'.format(i)
  print(url2)
  headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}
  webpage = requests.get(url,headers=headers).text
  soup = BeautifulSoup(webpage,'lxml')

  card_container = 'container-fluid'
  company2 = soup.find_all('div',class_='individual_internship_details')
  ctc3 = soup.find_all('div',class_='other_detail_item salary_container')
  exp5 = soup.find_all('div',class_='other_detail_item job-experience-item')
  job_profile = soup.find_all('h3',class_='heading_4_5 profile')
  company_name = soup.find_all('div',class_='heading_6 company_name')
  logo9 = soup.find_all('div',class_='internship_logo')

  location = []
  for i in company2:
   x3 = i.find('span')
   location.append(x3.text.strip())

  ctc = []
  for i in ctc3:
   x4 = i.find('span',class_='desktop')
   ctc.append(x4.text.strip())

  exp = []
  for i in exp5:
   x5 = i.find('div',class_='item_body desktop-text')
   exp.append(x5.text.strip())

  job = []
  cmpname = []
  logo = []


  for i in job_profile:
   x7 = i.text.strip()
   job.append(x7)

  for i in company_name:
   x8 = i.find('p')
   cmpname.append(x8.text.strip())

  for i in logo9:
   x9 = i.find('img')
   if x9:
     logo.append(x9['src'])
   else :
     logo.append('none')

  if i == 1:  # First page
        job = job[:47]  # Assuming the first page always has 47 rows
        cmpname = cmpname[:47]
        logo = logo[:47]
        location = location[:47]
        ctc = ctc[:47]
        exp = exp[:47]
  else:  # Other pages
        job = job[:40]  # Assuming other pages always have 40 rows
        cmpname = cmpname[:40]
        logo = logo[:40]
        location = location[:40]
        ctc = ctc[:40]
        exp = exp[:40]

  print(len(job))
  print(len(cmpname))
  print(len(logo))
  print(len(location))
  print(len(ctc))
  print(len(exp))


  merge2 = {'Job Profile':job,'Company':cmpname,'Location':location,'CTC':ctc,'EXPERIENCE':exp,'LOGO':logo}

  data = data.append(pd.DataFrame(merge2),ignore_index=True)

pd.DataFrame(merge2)

data

data['Location'].value_counts()

data.to_csv('output.csv', index=False)

